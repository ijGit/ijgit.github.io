{"version":3,"sources":["webpack:///./config/type.js","webpack:///./src/components/post-list/index.jsx","webpack:///./src/pages/search.jsx","webpack:///./node_modules/js-search/dist/esm/js-search.js","webpack:///./src/components/post-list/item.jsx","webpack:///./src/components/tags/index.jsx"],"names":["module","exports","Container","styled","div","PostList","posts","isSearchpage","map","node","title","frontmatter","tags","date","slug","fields","type","key","SearchContainer","SearchPage","data","edges","allMarkdownRemark","_node","id","excerpt","push","useState","search","setSearch","searchResults","setSearchResults","postList","setPostList","searchQuery","setSearchQuery","queryResults","setQueryResults","useEffect","dataToSearch","JsSearch","indexStrategy","sanitizer","searchIndex","addIndex","addDocuments","site","siteMetadata","siteData","className","onSubmit","e","preventDefault","style","padding","value","onChange","queryResult","target","placeholder","htmlFor","paddingLeft","icon","faSearch","length","PrefixIndexStrategy","prototype","expandToken","token","expandedTokens","string","i","charAt","LowerCaseSanitizer","sanitize","text","toLocaleLowerCase","trim","getNestedFieldValue","object","path","TfIdfSearchIndex","uidFieldName","this","_uidFieldName","_tokenToIdfCache","_tokenMap","_proto","indexDocument","uid","doc","tokenDatum","tokenMap","$numDocumentOccurrences","$totalNumOccurrences","$uidMap","uidMap","$document","$numTokenOccurrences","tokens","corpus","uidToDocumentMap","numTokens","tokenMetadata","j","numKeys","keys","Object","documents","calculateTfIdf","_createCalculateTfIdf","sort","documentA","documentB","_createCalculateIdf","tokenToIdfCache","numDocumentsWithToken","Math","log","calculateIdf","document","score","inverseDocumentFrequency","Infinity","Array","REGEX","SimpleTokenizer","tokenize","split","filter","_defineProperties","props","descriptor","enumerable","configurable","writable","defineProperty","Search","Error","_indexStrategy","_searchIndex","_sanitizer","_tokenizer","_documents","_searchableFields","Constructor","protoProps","staticProps","addDocument","concat","indexDocuments_","field","query","_initialized","tokenizer","di","numDocuments","sfi","numSearchableFields","fieldValue","searchableField","toString","fieldTokens","fti","numFieldValues","fieldToken","eti","nummExpandedTokens","expandedToken","set","get","PostItem","_type","to","TagsContainer","TagList","tag"],"mappings":"8EAAAA,EAAOC,QAAU,CACf,QAAW,KACX,KAAQ,GACR,QAAW,KACX,OAAU,KACV,KAAQ,MACR,OAAU,KACV,MAAS,KACT,KAAQ,KACR,QAAW,KACX,QAAW,KACX,OAAU,KACV,IAAO,KACP,KAAQ,KACR,KAAQ,KACR,MAAS,O,qCCfX,oFAKMC,EAAYC,IAAOC,IAAV,2EAAGD,CAAH,4OAwBFE,EAAW,SAAC,GAAgC,IAA/BC,EAA8B,EAA9BA,MAA8B,IAAvBC,oBAAuB,SACtD,OACE,gBAACL,EAAD,KACE,0BAEII,EAAME,KAAI,SAAAC,GACRA,EAAOF,EAAcE,EAASA,EAAKA,KACnC,IAAMC,EAAQH,EAAcE,EAAKC,MAAQD,EAAKE,YAAYD,MACpDE,EAAOL,EAAcE,EAAKG,KAAOH,EAAKE,YAAYC,KAClDC,EAAON,EAAcE,EAAKI,KAAOJ,EAAKE,YAAYE,KAClDC,EAAOP,EAAcE,EAAKK,KAAOL,EAAKM,OAAOD,KAC/CE,EAAOT,EAAcE,EAAKO,KAAOP,EAAKE,YAAYK,KAItD,OAFAA,EAAOA,QAAsC,UAAYA,EAGvD,sBAAIC,IAAOH,GACT,gBAAC,IAAD,CACEJ,MAAOA,EACPM,KAAMA,EACNJ,KAAMA,EACNC,KAAMA,EACNC,KAAMA,a,wDCnDxB,4JAWMI,EAXN,UAWwBf,EAAOC,IAAV,8EAAGD,CAAH,qPAkCN,SAASgB,EAAT,GAA+B,IAATC,EAAQ,EAARA,KAC3BC,EAAUD,EAAKE,kBAAfD,MAGJf,EAAQ,GACZe,EAAMb,KAAI,YAAe,IAAZC,EAAW,EAAXA,KACPc,EAAQ,CACVC,GAAIf,EAAKe,GACTV,KAAML,EAAKM,OAAOD,KAClBJ,MAAOD,EAAKE,YAAYD,MACxBG,KAAMJ,EAAKE,YAAYE,KACvBD,KAAMH,EAAKE,YAAYC,KACvBa,QAAShB,EAAKgB,SAEhBnB,EAAMoB,KAAKH,MAd8B,MAiBfI,mBAAS,IAA9BC,EAjBoC,KAiB5BC,EAjB4B,OAkBDF,mBAAS,IAA5CG,EAlBoC,KAkBrBC,EAlBqB,OAmBXJ,mBAAS,IAAlCK,EAnBoC,KAmB1BC,EAnB0B,OAoBLN,mBAAS,IAAxCO,EApBoC,KAoBvBC,EApBuB,OAqBHR,mBAASrB,GAA1C8B,EArBoC,KAqBtBC,EArBsB,KAsD3C,OALAC,qBAAU,WA1BW,IACbC,EA0BNN,EAAY3B,IA1BNiC,EAAe,IAAIC,IAAgB,OAC5BC,cAAgB,IAAID,IACjCD,EAAaG,UAAY,IAAIF,IAE7BD,EAAaI,YAAc,IAAIH,IAA0B,MAEzDD,EAAaK,SAAS,SACtBL,EAAaK,SAAS,WACtBL,EAAaK,SAAS,QACtBL,EAAaM,aAAavC,GAE1BuB,EAAUU,KAiBT,IAGD,kCACE,gBAAC,IAAD,CAAM7B,MAAOU,EAAK0B,KAAKC,aAAarC,QACpC,gBAAC,IAAD,CAAQsC,SAAU5B,EAAK0B,MACrB,2BAAStB,GAAG,WACV,gBAACN,EAAD,KACE,uBAAK+B,UAAU,eAAeC,SAfnB,SAAAC,GACnBA,EAAEC,mBAeQ,yBACE5B,GAAG,SACH6B,MAAO,CAAEC,QAAS,WAClBC,MAAOrB,EACPsB,SA3BK,SAAAL,GACjB,IAAMM,EAAc7B,EAAOA,OAAOuB,EAAEO,OAAOH,OAC3CpB,EAAegB,EAAEO,OAAOH,OACxBlB,EAAgC,KAAhBH,EAAqBF,EAAWF,GAChDC,EAAiB0B,IAwBLE,YAAY,2BAEd,yBAAOC,QAAQ,SAASP,MAAO,CAAEQ,YAAa,SAC5C,gBAAC,IAAD,CAAMC,KAAMC,QAIhB,uBAAKd,UAAU,gBAAf,mBACmBb,EAAa4B,SAIlC,gBAAC,IAAD,CAAUzD,cAAc,EAAMD,MAAO8B,S,wDC3H/C,wIAGA,IAkDI6B,EAAmC,WACrC,SAASA,KAmBT,OAjBaA,EAAoBC,UAK1BC,YAAc,SAAqBC,GAIxC,IAHA,IAAIC,EAAiB,GACjBC,EAAS,GAEJC,EAAI,EAAGP,EAASI,EAAMJ,OAAQO,EAAIP,IAAUO,EACnDD,GAAUF,EAAMI,OAAOD,GACvBF,EAAe3C,KAAK4C,GAGtB,OAAOD,GAGFJ,EApB8B,GA8CnCQ,EAAkC,WACpC,SAASA,KAWT,OATaA,EAAmBP,UAKzBQ,SAAW,SAAkBC,GAClC,OAAOA,EAAOA,EAAKC,oBAAoBC,OAAS,IAG3CJ,EAZ6B,GAuBtC,SAASK,EAAoBC,EAAQC,GACnCA,EAAOA,GAAQ,GAIf,IAFA,IAAIzB,EADJwB,EAASA,GAAU,GAGVR,EAAI,EAAGA,EAAIS,EAAKhB,OAAQO,IAG/B,GAAa,OAFbhB,EAAQA,EAAMyB,EAAKT,KAGjB,OAAO,KAIX,OAAOhB,EAOT,IAAI0B,EAAgC,WAClC,SAASA,EAAiBC,GACxBC,KAAKC,cAAgBF,EACrBC,KAAKE,iBAAmB,GACxBF,KAAKG,UAAY,GAOnB,IAAIC,EAASN,EAAiBf,UA+H9B,OA7HAqB,EAAOC,cAAgB,SAAuBpB,EAAOqB,EAAKC,GACxDP,KAAKE,iBAAmB,GAExB,IACIM,EADAC,EAAWT,KAAKG,UAGW,iBAApBM,EAASxB,GAClBwB,EAASxB,GAASuB,EAAa,CAC7BE,wBAAyB,EACzBC,qBAAsB,EACtBC,QAAS,KAGXJ,EAAaC,EAASxB,IACX0B,uBAGb,IAAIE,EAASL,EAAWI,QAEG,iBAAhBC,EAAOP,IAChBE,EAAWE,0BACXG,EAAOP,GAAO,CACZQ,UAAWP,EACXQ,qBAAsB,IAGxBF,EAAOP,GAAKS,wBAQhBX,EAAO3D,OAAS,SAAgBuE,EAAQC,GAGtC,IAFA,IAAIC,EAAmB,GAEd9B,EAAI,EAAG+B,EAAYH,EAAOnC,OAAQO,EAAI+B,EAAW/B,IAAK,CAC7D,IAAIH,EAAQ+B,EAAO5B,GACfgC,EAAgBpB,KAAKG,UAAUlB,GAEnC,IAAKmC,EACH,MAAO,GAGT,GAAU,IAANhC,EAGF,IAFA,IAESiC,EAAI,EAAGC,GAFZC,EAAOC,OAAOD,KAAKH,EAAcR,UAEN/B,OAAQwC,EAAIC,EAASD,IAAK,CAEvDH,EADIZ,EAAMiB,EAAKF,IACSD,EAAcR,QAAQN,GAAKQ,cAGrD,KAAIS,EAEJ,IAASF,EAAI,EAAGC,GAFZC,EAAOC,OAAOD,KAAKL,IAEQrC,OAAQwC,EAAIC,EAASD,IAAK,CACvD,IAAIf,EAAMiB,EAAKF,GAE2B,iBAA/BD,EAAcR,QAAQN,WACxBY,EAAiBZ,KAMhC,IAAImB,EAAY,GAEhB,IAAK,IAAInB,KAAOY,EACdO,EAAUlF,KAAK2E,EAAiBZ,IAGlC,IAAIoB,EAAiB1B,KAAK2B,wBAG1B,OAAOF,EAAUG,MAAK,SAAUC,EAAWC,GACzC,OAAOJ,EAAeV,EAAQc,EAAWb,GAAUS,EAAeV,EAAQa,EAAWZ,OAIzFb,EAAO2B,oBAAsB,WAC3B,IAAItB,EAAWT,KAAKG,UAChB6B,EAAkBhC,KAAKE,iBAC3B,OAAO,SAAsBjB,EAAOwC,GAClC,IAAKO,EAAgB/C,GAAQ,CAC3B,IAAIgD,OAAmD,IAApBxB,EAASxB,GAAyBwB,EAASxB,GAAOyB,wBAA0B,EAC/GsB,EAAgB/C,GAAS,EAAIiD,KAAKC,IAAIV,EAAU5C,QAAU,EAAIoD,IAGhE,OAAOD,EAAgB/C,KAI3BmB,EAAOuB,sBAAwB,WAC7B,IAAIlB,EAAWT,KAAKG,UAChBJ,EAAeC,KAAKC,cAEpBmC,EAAepC,KAAK+B,sBAExB,OAAO,SAAwBf,EAAQqB,EAAUZ,GAG/C,IAFA,IAAIa,EAAQ,EAEHlD,EAAI,EAAG+B,EAAYH,EAAOnC,OAAQO,EAAI+B,IAAa/B,EAAG,CAC7D,IAOIkB,EAPArB,EAAQ+B,EAAO5B,GACfmD,EAA2BH,EAAanD,EAAOwC,GAE/Cc,IAA6BC,MAC/BD,EAA2B,GAM3BjC,EADEP,aAAwB0C,MACpBJ,GAAY1C,EAAoB0C,EAAUtC,GAE1CsC,GAAYA,EAAStC,GAI7BuC,SAD+C,IAApB7B,EAASxB,SAAkE,IAAjCwB,EAASxB,GAAO2B,QAAQN,GAAuBG,EAASxB,GAAO2B,QAAQN,GAAKS,qBAAuB,GAC/IwB,EAG3B,OAAOD,IAIJxC,EA1I2B,GAsNhC4C,EAAQ,qBAKRC,EAA+B,WACjC,SAASA,KAcT,OAZaA,EAAgB5D,UAKtB6D,SAAW,SAAkBpD,GAClC,OAAOA,EAAKqD,MAAMH,GAAOI,QAAO,SAAUtD,GACxC,OAAOA,MAKJmD,EAf0B,GAyNnC,SAASI,EAAkBxE,EAAQyE,GACjC,IAAK,IAAI5D,EAAI,EAAGA,EAAI4D,EAAMnE,OAAQO,IAAK,CACrC,IAAI6D,EAAaD,EAAM5D,GACvB6D,EAAWC,WAAaD,EAAWC,aAAc,EACjDD,EAAWE,cAAe,EACtB,UAAWF,IAAYA,EAAWG,UAAW,GACjD5B,OAAO6B,eAAe9E,EAAQ0E,EAAWnH,IAAKmH,IAgBlD,IAAIK,EAAsB,WAUxB,SAASA,EAAOvD,GACd,IAAKA,EACH,MAAMwD,MAAM,6DAGdvD,KAAKC,cAAgBF,EAErBC,KAAKwD,eAAiB,IAAI1E,EAC1BkB,KAAKyD,aAAe,IAAI3D,EAAiBC,GACzCC,KAAK0D,WAAa,IAAIpE,EACtBU,KAAK2D,WAAa,IAAIhB,EACtB3C,KAAK4D,WAAa,GAClB5D,KAAK6D,kBAAoB,GAS3B,IA3CoBC,EAAaC,EAAYC,EA2CzC5D,EAASkD,EAAOvE,UAuKpB,OAjKAqB,EAAO6D,YAAc,SAAqB5B,GACxCrC,KAAKtC,aAAa,CAAC2E,KAQrBjC,EAAO1C,aAAe,SAAsB+D,GAC1CzB,KAAK4D,WAAa5D,KAAK4D,WAAWM,OAAOzC,GACzCzB,KAAKmE,gBAAgB1C,EAAWzB,KAAK6D,oBASvCzD,EAAO3C,SAAW,SAAkB2G,GAClCpE,KAAK6D,kBAAkBtH,KAAK6H,GAE5BpE,KAAKmE,gBAAgBnE,KAAK4D,WAAY,CAACQ,KASzChE,EAAO3D,OAAS,SAAgB4H,GAC9B,IAAIrD,EAAShB,KAAK2D,WAAWf,SAAS5C,KAAK0D,WAAWnE,SAAS8E,IAE/D,OAAOrE,KAAKyD,aAAahH,OAAOuE,EAAQhB,KAAK4D,aAS/CxD,EAAO+D,gBAAkB,SAAyB1C,EAAWoC,GAC3D7D,KAAKsE,cAAe,EAOpB,IANA,IAAIhH,EAAgB0C,KAAKwD,eACrBjG,EAAYyC,KAAK0D,WACjBlG,EAAcwC,KAAKyD,aACnBc,EAAYvE,KAAK2D,WACjB5D,EAAeC,KAAKC,cAEfuE,EAAK,EAAGC,EAAehD,EAAU5C,OAAQ2F,EAAKC,EAAcD,IAAM,CACzE,IACIlE,EADAC,EAAMkB,EAAU+C,GAIlBlE,EADEP,aAAwB0C,MACpB9C,EAAoBY,EAAKR,GAEzBQ,EAAIR,GAGZ,IAAK,IAAI2E,EAAM,EAAGC,EAAsBd,EAAkBhF,OAAQ6F,EAAMC,EAAqBD,IAAO,CAClG,IAAIE,EACAC,EAAkBhB,EAAkBa,GAYxC,GAJkB,OALhBE,EADEC,aAA2BpC,MAChB9C,EAAoBY,EAAKsE,GAEzBtE,EAAIsE,KAG6B,iBAAfD,GAA2BA,EAAWE,WACrEF,EAAaA,EAAWE,YAGA,iBAAfF,EAGT,IAFA,IAAIG,EAAcR,EAAU3B,SAASrF,EAAUgC,SAASqF,IAE/CI,EAAM,EAAGC,EAAiBF,EAAYlG,OAAQmG,EAAMC,EAAgBD,IAI3E,IAHA,IAAIE,EAAaH,EAAYC,GACzB9F,EAAiB5B,EAAc0B,YAAYkG,GAEtCC,EAAM,EAAGC,EAAqBlG,EAAeL,OAAQsG,EAAMC,EAAoBD,IAAO,CAC7F,IAAIE,EAAgBnG,EAAeiG,GACnC3H,EAAY6C,cAAcgF,EAAe/E,EAAKC,OAtItCuD,EA8IPR,GA9IoBS,EA8IZ,CAAC,CACpBjI,IAAK,gBACLwJ,IAAK,SAAalH,GAChB,GAAI4B,KAAKsE,aACP,MAAMf,MAAM,qDAGdvD,KAAKwD,eAAiBpF,GAExBmH,IAAK,WACH,OAAOvF,KAAKwD,iBAQb,CACD1H,IAAK,YACLwJ,IAAK,SAAalH,GAChB,GAAI4B,KAAKsE,aACP,MAAMf,MAAM,iDAGdvD,KAAK0D,WAAatF,GAEpBmH,IAAK,WACH,OAAOvF,KAAK0D,aAQb,CACD5H,IAAK,cACLwJ,IAAK,SAAalH,GAChB,GAAI4B,KAAKsE,aACP,MAAMf,MAAM,mDAGdvD,KAAKyD,aAAerF,GAEtBmH,IAAK,WACH,OAAOvF,KAAKyD,eAQb,CACD3H,IAAK,YACLwJ,IAAK,SAAalH,GAChB,GAAI4B,KAAKsE,aACP,MAAMf,MAAM,iDAGdvD,KAAK2D,WAAavF,GAEpBmH,IAAK,WACH,OAAOvF,KAAK2D,gBA7MAZ,EAAkBe,EAAY/E,UAAWgF,GACrDC,GAAajB,EAAkBe,EAAaE,GAgNzCV,EAtMiB,I,mCCxlB1B,qHAMMvI,EAAYC,IAAOC,IAAV,kEAAGD,CAAH,4+BAuFFwK,EAAW,SAAC,GAAuC,IAArCjK,EAAoC,EAApCA,MAAOM,EAA6B,EAA7BA,KAAMJ,EAAuB,EAAvBA,KAAMC,EAAiB,EAAjBA,KAAMC,EAAW,EAAXA,KAClD,OACI,gBAACZ,EAAD,KACE,uBAAK+C,UAAU,SACb,uBAAKA,UAAU,cACZ2H,IAAM5J,IAGT,gBAAC,IAAD,CAAM6J,GAAI/J,GAAM,wBAAMmC,UAAU,cAAcvC,KAEhD,uBAAKuC,UAAU,QACb,uBAAKA,UAAU,QAAO,gBAAC,IAAD,CAASrC,KAAMA,KACrC,uBAAKqC,UAAU,QAAQpC,Q,yDCzGjC,4DAGMiK,EAHN,UAGsB3K,EAAOC,IAAV,0EAAGD,CAAH,iJAgBN4K,EAAU,SAAC,GAAc,IAAZnK,EAAW,EAAXA,KACxB,OACE,gBAACkK,EAAD,KACGlK,EAAKJ,KAAI,SAAAwK,GACR,OAAQ,wBAAM/H,UAAU,WAAWhC,IAAK+J,GAAMA,U","file":"component---src-pages-search-jsx-756b0e235d12162dcf2c.js","sourcesContent":["module.exports = {\n  'default': '📄',\n  'main': '',\n  'snippet': '🧩',\n  'design': '🎨',\n  'tool': '🛠️',\n  'theory': '📚',\n  'study': '📚',\n  'term': '📒',\n  'develop': '💻',\n  'problem': '🔑',\n  'review': '📰',\n  'ref': '💬',\n  'memo': '📌',\n  'note': '✏️',\n  'error': '🚨',\n}\n\n// 📅 💬 🗝 🔑 🗒 🗃 ⚠️ 💻 💾 🤖 🛠 🚩 🔧🔬📰😎👨🏻‍💻\n//'note': '🖋️',","import React from \"react\"\nimport styled from \"styled-components\"\nimport { PostItem } from \"./item\"\n\n\nconst Container = styled.div`\n  display: flex;\n  flex-direction: column;\n\n  ul{\n    list-style: none;\n    margin-left: 0;\n    margin: 0px;\n    padding: 0px;\n\n    li{\n      list-style: none;\n      margin-left: 0;\n      margin: 0px;\n      padding: 0px;\n      border-bottom: 1px solid #8383837e;\n    }\n    li:first-child{\n      border-top: 1px solid #8383837e;\n    }\n  }\n`\n\n\nexport const PostList = ({posts, isSearchpage=false}) =>{\n  return(\n    <Container>\n      <ul>\n        {\n          posts.map(node=> {\n            node = isSearchpage? node : ((node.node));\n            const title = isSearchpage? node.title : node.frontmatter.title\n            const tags = isSearchpage? node.tags : node.frontmatter.tags\n            const date = isSearchpage? node.date : node.frontmatter.date\n            const slug = isSearchpage? node.slug : node.fields.slug\n            var type = isSearchpage? node.type : node.frontmatter.type\n\n            type = type === null || type === undefined ? 'default' : type;\n            \n            return(\n              <li key = {slug}>\n                <PostItem\n                  title={title}\n                  type={type}\n                  tags={tags}\n                  date={date}\n                  slug={slug}/>\n              </li>\n            )\n          })\n        }\n      </ul>\n    </Container>\n  )\n}\n","import React, { useEffect, useState } from \"react\"\nimport { Layout } from \"../components/layout/layout\"\nimport { graphql } from \"gatsby\"\nimport { Head } from \"./../components/head/head\"\nimport * as JsSearch from \"js-search\"\nimport { faSearch } from \"@fortawesome/free-solid-svg-icons\"\nimport {PostList} from './../components/post-list/'\nimport {Icon} from './../components/icon'\nimport styled from \"styled-components\"\n\n\nconst SearchContainer = styled.div`\ndisplay: flex;\nwidth: 100%;\nmax-width: 600px;\nflex-direction: column;\nmargin: 0 auto;\nmargin-bottom: 10vh;\n\n.search-input{\n  justify-content: center;\n  align-items: center;\n  display: flex;\n  input{\n    flex: auto;\n  }\n}\n.search-count{\n  display: flex;\n  margin-right: auto;\n  opacity: .7;\n}\n`\n\n/*\nconst _SearchContainer = styled.div`\n  input{\n    border: none;\n    -webkit-border-radius: 5px;\n    -moz-border-radius: 5px;\n    border-radius: 5px;\n  }\n`\n*/\n\nexport default function SearchPage({ data }) {\n  const { edges } = data.allMarkdownRemark\n\n  // need make new json array\n  var posts = []\n  edges.map(({ node }) => {\n    var _node = {\n      id: node.id,\n      slug: node.fields.slug,\n      title: node.frontmatter.title,\n      date: node.frontmatter.date,\n      tags: node.frontmatter.tags,\n      excerpt: node.excerpt,\n    }\n    posts.push(_node)\n  })\n\n  const [search, setSearch] = useState([])\n  const [searchResults, setSearchResults] = useState([])\n  const [postList, setPostList] = useState([])\n  const [searchQuery, setSearchQuery] = useState(\"\")\n  const [queryResults, setQueryResults] = useState(posts)\n\n  const rebuildIndex = () => {\n    const dataToSearch = new JsSearch.Search(\"id\")\n    dataToSearch.indexStrategy = new JsSearch.PrefixIndexStrategy()\n    dataToSearch.sanitizer = new JsSearch.LowerCaseSanitizer()\n\n    dataToSearch.searchIndex = new JsSearch.TfIdfSearchIndex(\"id\")\n\n    dataToSearch.addIndex(\"title\")\n    dataToSearch.addIndex(\"excerpt\")\n    dataToSearch.addIndex(\"tags\")\n    dataToSearch.addDocuments(posts)\n\n    setSearch(dataToSearch)\n  }\n\n  const searchData = e => {\n    const queryResult = search.search(e.target.value)\n    setSearchQuery(e.target.value)\n    setQueryResults(searchQuery === \"\" ? postList : searchResults)\n    setSearchResults(queryResult)\n  }\n\n  const handleSubmit = e => {\n    e.preventDefault()\n  }\n\n  useEffect(() => {\n    setPostList(posts)\n    rebuildIndex()\n  }, [])\n\n  return (\n    <>\n      <Head title={data.site.siteMetadata.title} />\n      <Layout siteData={data.site}>\n        <section id=\"content\">\n          <SearchContainer>\n            <div className='search-input' onSubmit={handleSubmit}>\n              <input\n                id=\"Search\"\n                style={{ padding: \"4px 8px\" }}\n                value={searchQuery}\n                onChange={searchData}\n                placeholder=\"Enter your search here\"\n              />\n              <label htmlFor=\"Search\" style={{ paddingLeft: \"10px\" }}>\n                <Icon icon={faSearch}/>\n              </label>\n            </div>\n\n            <div className='search-count'>\n              search result : {queryResults.length}\n            </div>\n          </SearchContainer>\n\n          <PostList isSearchpage={true} posts={queryResults}/>\n        </section>\n      </Layout>\n    </>\n  )\n}\n\nexport const pageQuery = graphql`\n  query {\n    site {\n      siteMetadata {\n        title\n      }\n      pathPrefix\n    }\n    allMarkdownRemark(sort: { fields: [frontmatter___date], order: DESC } \n      filter: {frontmatter: {draft: {ne: false}}}) {\n      edges {\n        node {\n          id\n          fields {\n            slug\n          }\n          excerpt\n          frontmatter {\n            date(formatString: \"YYYY-MM-DD\")\n            tags\n            title\n            type\n          }\n        }\n      }\n    }\n  }\n`\n","/**\n * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n */\nvar AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n  function AllSubstringsIndexStrategy() {}\n\n  var _proto = AllSubstringsIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string;\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string = '';\n\n      for (var j = i; j < length; ++j) {\n        string += token.charAt(j);\n        expandedTokens.push(string);\n      }\n    }\n\n    return expandedTokens;\n  };\n\n  return AllSubstringsIndexStrategy;\n}();\n/**\n * Indexes for exact word matches.\n */\n\n\nvar ExactWordIndexStrategy = /*#__PURE__*/function () {\n  function ExactWordIndexStrategy() {}\n\n  var _proto = ExactWordIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    return token ? [token] : [];\n  };\n\n  return ExactWordIndexStrategy;\n}();\n/**\n * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n */\n\n\nvar PrefixIndexStrategy = /*#__PURE__*/function () {\n  function PrefixIndexStrategy() {}\n\n  var _proto = PrefixIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string = '';\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string += token.charAt(i);\n      expandedTokens.push(string);\n    }\n\n    return expandedTokens;\n  };\n\n  return PrefixIndexStrategy;\n}();\n/**\n * Enforces case-sensitive text matches.\n */\n\n\nvar CaseSensitiveSanitizer = /*#__PURE__*/function () {\n  function CaseSensitiveSanitizer() {}\n\n  var _proto = CaseSensitiveSanitizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.trim() : '';\n  };\n\n  return CaseSensitiveSanitizer;\n}();\n/**\n * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n */\n\n\nvar LowerCaseSanitizer = /*#__PURE__*/function () {\n  function LowerCaseSanitizer() {}\n\n  var _proto = LowerCaseSanitizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.toLocaleLowerCase().trim() : '';\n  };\n\n  return LowerCaseSanitizer;\n}();\n/**\n * Find and return a nested object value.\n *\n * @param object to crawl\n * @param path Property path\n * @returns {any}\n */\n\n\nfunction getNestedFieldValue(object, path) {\n  path = path || [];\n  object = object || {};\n  var value = object; // walk down the property path\n\n  for (var i = 0; i < path.length; i++) {\n    value = value[path[i]];\n\n    if (value == null) {\n      return null;\n    }\n  }\n\n  return value;\n}\n/**\n * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n */\n\n\nvar TfIdfSearchIndex = /*#__PURE__*/function () {\n  function TfIdfSearchIndex(uidFieldName) {\n    this._uidFieldName = uidFieldName;\n    this._tokenToIdfCache = {};\n    this._tokenMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = TfIdfSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n    var tokenMap = this._tokenMap;\n    var tokenDatum;\n\n    if (typeof tokenMap[token] !== 'object') {\n      tokenMap[token] = tokenDatum = {\n        $numDocumentOccurrences: 0,\n        $totalNumOccurrences: 1,\n        $uidMap: {}\n      };\n    } else {\n      tokenDatum = tokenMap[token];\n      tokenDatum.$totalNumOccurrences++;\n    }\n\n    var uidMap = tokenDatum.$uidMap;\n\n    if (typeof uidMap[uid] !== 'object') {\n      tokenDatum.$numDocumentOccurrences++;\n      uidMap[uid] = {\n        $document: doc,\n        $numTokenOccurrences: 1\n      };\n    } else {\n      uidMap[uid].$numTokenOccurrences++;\n    }\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var uidToDocumentMap = {};\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!tokenMetadata) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(tokenMetadata.$uidMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n        }\n      } else {\n        var keys = Object.keys(uidToDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n            delete uidToDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var documents = [];\n\n    for (var uid in uidToDocumentMap) {\n      documents.push(uidToDocumentMap[uid]);\n    }\n\n    var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n    return documents.sort(function (documentA, documentB) {\n      return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n    });\n  };\n\n  _proto._createCalculateIdf = function _createCalculateIdf() {\n    var tokenMap = this._tokenMap;\n    var tokenToIdfCache = this._tokenToIdfCache;\n    return function calculateIdf(token, documents) {\n      if (!tokenToIdfCache[token]) {\n        var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n        tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n      }\n\n      return tokenToIdfCache[token];\n    };\n  };\n\n  _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n    var tokenMap = this._tokenMap;\n    var uidFieldName = this._uidFieldName;\n\n    var calculateIdf = this._createCalculateIdf();\n\n    return function calculateTfIdf(tokens, document, documents) {\n      var score = 0;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n        var token = tokens[i];\n        var inverseDocumentFrequency = calculateIdf(token, documents);\n\n        if (inverseDocumentFrequency === Infinity) {\n          inverseDocumentFrequency = 0;\n        }\n\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = document && getNestedFieldValue(document, uidFieldName);\n        } else {\n          uid = document && document[uidFieldName];\n        }\n\n        var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n        score += termFrequency * inverseDocumentFrequency;\n      }\n\n      return score;\n    };\n  };\n\n  return TfIdfSearchIndex;\n}();\n/**\n * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n */\n\n\nvar UnorderedSearchIndex = /*#__PURE__*/function () {\n  function UnorderedSearchIndex() {\n    this._tokenToUidToDocumentMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = UnorderedSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n      this._tokenToUidToDocumentMap[token] = {};\n    }\n\n    this._tokenToUidToDocumentMap[token][uid] = doc;\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var intersectingDocumentMap = {};\n    var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!documentMap) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(documentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          intersectingDocumentMap[uid] = documentMap[uid];\n        }\n      } else {\n        var keys = Object.keys(intersectingDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof documentMap[uid] !== 'object') {\n            delete intersectingDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var keys = Object.keys(intersectingDocumentMap);\n    var documents = [];\n\n    for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n      var uid = keys[i];\n      documents.push(intersectingDocumentMap[uid]);\n    }\n\n    return documents;\n  };\n\n  return UnorderedSearchIndex;\n}();\n\nvar REGEX = /[^a-zа-яё0-9\\-']+/i;\n/**\n * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n */\n\nvar SimpleTokenizer = /*#__PURE__*/function () {\n  function SimpleTokenizer() {}\n\n  var _proto = SimpleTokenizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.tokenize = function tokenize(text) {\n    return text.split(REGEX).filter(function (text) {\n      return text;\n    } // Filter empty tokens\n    );\n  };\n\n  return SimpleTokenizer;\n}();\n/**\n * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n *\n * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n *\n * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n */\n\n\nvar StemmingTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param stemmingFunction Function capable of accepting a word and returning its stem.\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n    this._stemmingFunction = stemmingFunction;\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StemmingTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n  };\n\n  return StemmingTokenizer;\n}();\n/**\n * Stop words list copied from Lunr JS.\n */\n\n\nvar StopWordsMap = {\n  a: true,\n  able: true,\n  about: true,\n  across: true,\n  after: true,\n  all: true,\n  almost: true,\n  also: true,\n  am: true,\n  among: true,\n  an: true,\n  and: true,\n  any: true,\n  are: true,\n  as: true,\n  at: true,\n  be: true,\n  because: true,\n  been: true,\n  but: true,\n  by: true,\n  can: true,\n  cannot: true,\n  could: true,\n  dear: true,\n  did: true,\n  'do': true,\n  does: true,\n  either: true,\n  'else': true,\n  ever: true,\n  every: true,\n  'for': true,\n  from: true,\n  'get': true,\n  got: true,\n  had: true,\n  has: true,\n  have: true,\n  he: true,\n  her: true,\n  hers: true,\n  him: true,\n  his: true,\n  how: true,\n  however: true,\n  i: true,\n  'if': true,\n  'in': true,\n  into: true,\n  is: true,\n  it: true,\n  its: true,\n  just: true,\n  least: true,\n  \"let\": true,\n  like: true,\n  likely: true,\n  may: true,\n  me: true,\n  might: true,\n  most: true,\n  must: true,\n  my: true,\n  neither: true,\n  no: true,\n  nor: true,\n  not: true,\n  of: true,\n  off: true,\n  often: true,\n  on: true,\n  only: true,\n  or: true,\n  other: true,\n  our: true,\n  own: true,\n  rather: true,\n  said: true,\n  say: true,\n  says: true,\n  she: true,\n  should: true,\n  since: true,\n  so: true,\n  some: true,\n  than: true,\n  that: true,\n  the: true,\n  their: true,\n  them: true,\n  then: true,\n  there: true,\n  these: true,\n  they: true,\n  'this': true,\n  tis: true,\n  to: true,\n  too: true,\n  twas: true,\n  us: true,\n  wants: true,\n  was: true,\n  we: true,\n  were: true,\n  what: true,\n  when: true,\n  where: true,\n  which: true,\n  'while': true,\n  who: true,\n  whom: true,\n  why: true,\n  will: true,\n  'with': true,\n  would: true,\n  yet: true,\n  you: true,\n  your: true\n}; // Prevent false positives for inherited properties\n\nStopWordsMap.constructor = false;\nStopWordsMap.hasOwnProperty = false;\nStopWordsMap.isPrototypeOf = false;\nStopWordsMap.propertyIsEnumerable = false;\nStopWordsMap.toLocaleString = false;\nStopWordsMap.toString = false;\nStopWordsMap.valueOf = false;\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\nvar StopWordsTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StopWordsTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).filter(function (token) {\n      return !StopWordsMap[token];\n    });\n  };\n\n  return StopWordsTokenizer;\n}();\n\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n/**\n * Simple client-side searching within a set of documents.\n *\n * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n */\n\n\nvar Search = /*#__PURE__*/function () {\n  /**\n   * Array containing either a property name or a path (list of property names) to a nested value\n   */\n\n  /**\n   * Constructor.\n   * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n   *                     to ensure that a search result set does not contain duplicate objects.\n   */\n  function Search(uidFieldName) {\n    if (!uidFieldName) {\n      throw Error('js-search requires a uid field name constructor parameter');\n    }\n\n    this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n    this._indexStrategy = new PrefixIndexStrategy();\n    this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n    this._sanitizer = new LowerCaseSanitizer();\n    this._tokenizer = new SimpleTokenizer();\n    this._documents = [];\n    this._searchableFields = [];\n  }\n  /**\n   * Override the default index strategy.\n   * @param value Custom index strategy\n   * @throws Error if documents have already been indexed by this search instance\n   */\n\n\n  var _proto = Search.prototype;\n  /**\n   * Add a searchable document to the index. Document will automatically be indexed for search.\n   * @param document\n   */\n\n  _proto.addDocument = function addDocument(document) {\n    this.addDocuments([document]);\n  }\n  /**\n   * Adds searchable documents to the index. Documents will automatically be indexed for search.\n   * @param document\n   */\n  ;\n\n  _proto.addDocuments = function addDocuments(documents) {\n    this._documents = this._documents.concat(documents);\n    this.indexDocuments_(documents, this._searchableFields);\n  }\n  /**\n   * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n   *\n   * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n   */\n  ;\n\n  _proto.addIndex = function addIndex(field) {\n    this._searchableFields.push(field);\n\n    this.indexDocuments_(this._documents, [field]);\n  }\n  /**\n   * Search all documents for ones matching the specified query text.\n   * @param query\n   * @returns {Array<Object>}\n   */\n  ;\n\n  _proto.search = function search(query) {\n    var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n    return this._searchIndex.search(tokens, this._documents);\n  }\n  /**\n   * @param documents\n   * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n   * @private\n   */\n  ;\n\n  _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n    this._initialized = true;\n    var indexStrategy = this._indexStrategy;\n    var sanitizer = this._sanitizer;\n    var searchIndex = this._searchIndex;\n    var tokenizer = this._tokenizer;\n    var uidFieldName = this._uidFieldName;\n\n    for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n      var doc = documents[di];\n      var uid;\n\n      if (uidFieldName instanceof Array) {\n        uid = getNestedFieldValue(doc, uidFieldName);\n      } else {\n        uid = doc[uidFieldName];\n      }\n\n      for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n        var fieldValue;\n        var searchableField = _searchableFields[sfi];\n\n        if (searchableField instanceof Array) {\n          fieldValue = getNestedFieldValue(doc, searchableField);\n        } else {\n          fieldValue = doc[searchableField];\n        }\n\n        if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n          fieldValue = fieldValue.toString();\n        }\n\n        if (typeof fieldValue === 'string') {\n          var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n          for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n            var fieldToken = fieldTokens[fti];\n            var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n            for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n              var expandedToken = expandedTokens[eti];\n              searchIndex.indexDocument(expandedToken, uid, doc);\n            }\n          }\n        }\n      }\n    }\n  };\n\n  _createClass(Search, [{\n    key: \"indexStrategy\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('IIndexStrategy cannot be set after initialization');\n      }\n\n      this._indexStrategy = value;\n    },\n    get: function get() {\n      return this._indexStrategy;\n    }\n    /**\n     * Override the default text sanitizing strategy.\n     * @param value Custom text sanitizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"sanitizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISanitizer cannot be set after initialization');\n      }\n\n      this._sanitizer = value;\n    },\n    get: function get() {\n      return this._sanitizer;\n    }\n    /**\n     * Override the default search index strategy.\n     * @param value Custom search index strategy\n     * @throws Error if documents have already been indexed\n     */\n\n  }, {\n    key: \"searchIndex\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISearchIndex cannot be set after initialization');\n      }\n\n      this._searchIndex = value;\n    },\n    get: function get() {\n      return this._searchIndex;\n    }\n    /**\n     * Override the default text tokenizing strategy.\n     * @param value Custom text tokenizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"tokenizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ITokenizer cannot be set after initialization');\n      }\n\n      this._tokenizer = value;\n    },\n    get: function get() {\n      return this._tokenizer;\n    }\n  }]);\n\n  return Search;\n}();\n/**\n * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n * of match criteria within searchable fields.\n *\n * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n */\n\n\nvar TokenHighlighter = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param opt_indexStrategy Index strategy used by Search\n   * @param opt_sanitizer Sanitizer used by Search\n   * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n   */\n  function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n    this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n    this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n    this._wrapperTagName = opt_wrapperTagName || 'mark';\n  }\n  /**\n   * Highlights token occurrences within a string by wrapping them with a DOM element.\n   *\n   * @param text e.g. \"john wayne\"\n   * @param tokens e.g. [\"wa\"]\n   * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n   */\n\n\n  var _proto = TokenHighlighter.prototype;\n\n  _proto.highlight = function highlight(text, tokens) {\n    var tagsLength = this._wrapText('').length;\n\n    var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = this._sanitizer.sanitize(tokens[i]);\n\n      var expandedTokens = this._indexStrategy.expandToken(token);\n\n      for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n        var expandedToken = expandedTokens[j];\n\n        if (!tokenDictionary[expandedToken]) {\n          tokenDictionary[expandedToken] = [token];\n        } else {\n          tokenDictionary[expandedToken].push(token);\n        }\n      }\n    } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n    var actualCurrentWord = '';\n    var sanitizedCurrentWord = '';\n    var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n    for (var i = 0, textLength = text.length; i < textLength; i++) {\n      var character = text.charAt(i);\n\n      if (character === ' ') {\n        actualCurrentWord = '';\n        sanitizedCurrentWord = '';\n        currentWordStartIndex = i + 1;\n      } else {\n        actualCurrentWord += character;\n        sanitizedCurrentWord += this._sanitizer.sanitize(character);\n      }\n\n      if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n        actualCurrentWord = this._wrapText(actualCurrentWord);\n        text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n        i += tagsLength;\n        textLength += tagsLength;\n      }\n    }\n\n    return text;\n  }\n  /**\n   * @param text to wrap\n   * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n   * @private\n   */\n  ;\n\n  _proto._wrapText = function _wrapText(text) {\n    var tagName = this._wrapperTagName;\n    return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n  };\n\n  return TokenHighlighter;\n}();\n\nexport { AllSubstringsIndexStrategy, CaseSensitiveSanitizer, ExactWordIndexStrategy, LowerCaseSanitizer, PrefixIndexStrategy, Search, SimpleTokenizer, StemmingTokenizer, StopWordsMap, StopWordsTokenizer, TfIdfSearchIndex, TokenHighlighter, UnorderedSearchIndex };","import React from \"react\"\nimport {TagList} from '../tags'\nimport { Link } from \"gatsby\"\nimport styled from \"styled-components\"\nimport _type from './../../../config/type'\n\nconst Container = styled.div`\n  display: flex;\n  flex-direction: row;\n  justify-content: space-between;\n  align-items: center;\n  \n  padding: 3vh 0;\n  \n  @media screen and (max-width: 479px){\n    flex-direction: column;\n  }\n  \n  .title{\n    width: 60%;\n    max-width: 60%;\n    display: flex;\n    margin-right: auto;\n    align-items: center;\n    flex-direction: row;\n    \n    .title-type{\n      align-items: stretch;\n      margin-right: 4px;\n      margin-bottom: auto;\n\n      line-height: 1.3;\n      font-size: 1em;\n    }\n    \n    .title-text{\n      display: -webkit-box;\n      -webkit-line-clamp: 2; \n      -webkit-box-orient: vertical;\n      height: 2.6;\n      \n      overflow: hidden;\n      text-overflow: ellipsis;\n      \n      font-weight: 500;\n      line-height: 1.3;\n      font-size: 1em;\n      \n      @media screen and (max-width: 479px){\n        height: 1.3;\n        -webkit-line-clamp: 1; \n      }\n    }\n    \n    @media screen and (max-width: 479px){\n      width: 100%;\n      max-width: 100%;\n      margin-bottom: .8em;\n    }    \n  }\n\n  .meta{\n    display: flex;\n    width: 35%;\n    max-width: 35%;\n    justify-content: flex-end;\n    \n    @media screen and (max-width: 479px){\n      width: 100%;\n      max-width: 100%;\n      justify-content: flex-start;\n    }\n\n    .tags{\n      display: inline-flex;\n      \n      .item {\n        margin-right: 0.5rem;\n      }\n      .item:before {\n        content: \"#\";\n      }\n    }\n    .date{\n      display: inline-flex;\n      font-size: 0.85rem;\n      opacity: 0.9;\n      white-space: nowrap;\n    }\n  }\n`\n\n\nexport const PostItem = ({ title, type, tags, date, slug }) => {\n  return (\n      <Container>\n        <div className='title'>\n          <div className='title-type'>\n            {_type[type]}\n            {/*<Icon name={type} icon={{'width':17, 'height':17}} />*/}\n          </div>\n          <Link to={slug}><span className='title-text'>{title}</span></Link>\n        </div>\n        <div className='meta'>\n          <div className='tags'><TagList tags={tags} /></div>\n          <div className='date'>{date}</div>\n        </div>\n      </Container>\n  )\n}\n","import React from \"react\"\nimport styled from \"styled-components\"\n\nconst TagsContainer = styled.div` \n  display: inline-block;\n\n  font-size: 0.85rem;\n  opacity: 0.5;\n  \n  .tag-item{\n    opacity: 1;\n    margin-right: .5rem;\n  }\n  .tag-item:hover{\n    opacity: 1;\n    margin-right: .5rem;\n  }\n`\n\nexport const TagList = ({ tags }) => {\n  return(\n    <TagsContainer>\n      {tags.map(tag => {\n        return (<span className='tag-item' key={tag}>{tag}</span>)\n      })}\n    </TagsContainer>\n  )\n}"],"sourceRoot":""}